{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "image_rows = 64\n",
    "image_columns = 64\n",
    "image_depth = 18\n",
    "\n",
    "flow_rows = 144\n",
    "flow_columns = 120\n",
    "flow_depth = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure for LOSOCV validation by conbining\n",
    "# model can be 'DS' which stands for Double Stream, 'DS_domain' stands for Double Stream with discriminator\n",
    "def getLOSOCV(model, Dataset, CK):\n",
    "    if(isinstance(Dataset, list)):\n",
    "        training_set, labels, subject_boundary, flow_set = Dataset[0], Dataset[1], Dataset[2], Dataset[3]\n",
    "        sample = Dataset[0].shape[0]\n",
    "    else:\n",
    "        training_set, labels, subject_boundary, flow_set = np.load(Dataset+ '/' + Dataset + '_set.npy' ), np.load(Dataset+ '/' + Dataset + '_labels.npy' ), np.load(Dataset+ '/' + Dataset + '_subject_boundary.npy'), np.load(Dataset+ '/' + Dataset + '_flow.npy')\n",
    "        sample = training_set.shape[0]\n",
    "        \n",
    "    if(isinstance(CK, list) and CK):\n",
    "        CK_training_set, CK_labels, CK_flow = CK[0], CK[1], CK[2]\n",
    "        CK_num = 327\n",
    "    else:\n",
    "        if(isinstance(CK, list) and not CK):\n",
    "            CK_num = 0\n",
    "        elif (CK == 'CK+'):\n",
    "            CK_num = 327\n",
    "            CK_training_set, CK_labels, CK_flow = np.load(\"CK+/CK_set.npy\") , np.load(\"CK+/CK_labels.npy\"), np.load('CK+/CK_flow.npy')\n",
    "    \n",
    "    LOSOCV = []\n",
    "\n",
    "    \n",
    "    print(\"Sample size: \", sample)\n",
    "    \n",
    "    for i in range(len(subject_boundary) - 1):    \n",
    "        # 0 is for micro-expression dataset and 1 is for CK+ dataset\n",
    "\n",
    "        training_images = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 1, image_rows, image_columns, image_depth))\n",
    "        training_labels = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 3))\n",
    "        training_domain_labels = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num))\n",
    "        training_flow_images = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 1, flow_rows, flow_columns, flow_depth))\n",
    "\n",
    "        verification_images = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 1, image_rows, image_columns, image_depth))\n",
    "        verification_labels = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 3))\n",
    "        verification_domain_labels = np.zeros((subject_boundary[i + 1] - subject_boundary[i]))\n",
    "        verification_flow_images = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 1, flow_rows, flow_columns, flow_depth))\n",
    "\n",
    "        for j in range(sample):\n",
    "            if (j >= subject_boundary[i] and j < subject_boundary[i + 1]):\n",
    "                verification_images[j-subject_boundary[i]][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "                verification_labels[j-subject_boundary[i]][:] = labels[j][:]\n",
    "                verification_flow_images[j-subject_boundary[i]][0][:][:][:] = flow_set[j][0][:][:][:]\n",
    "            elif (j < subject_boundary[i]):\n",
    "                training_images[j][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "                training_labels[j][:] = labels[j][:]\n",
    "                training_flow_images[j][0][:][:][:] = flow_set[j][0][:][:][:]\n",
    "            else:\n",
    "                training_images[j - subject_boundary[i+1] + subject_boundary[i]][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "                training_labels[j - subject_boundary[i+1] + subject_boundary[i]][:] = labels[j][:]\n",
    "                training_flow_images[j - subject_boundary[i+1] + subject_boundary[i]][0][:][:][:] = flow_set[j][0][:][:][:]\n",
    "\n",
    "        if(CK == 'CK+' or (isinstance(CK, list) and CK)):\n",
    "            for k in range(327):\n",
    "                training_images[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][0][:][:][:] = CK_training_set[k][0][:][:][:]\n",
    "                training_labels[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][:] = CK_labels[k][:]\n",
    "                training_domain_labels[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k] = 1\n",
    "                training_flow_images[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][0][:][:][:] = CK_flow[k][0][:][:][:]\n",
    "\n",
    "        if(model == 'DS'):\n",
    "            LOSOCV.append([training_images, training_flow_images, training_labels, verification_images, verification_flow_images, verification_labels])\n",
    "        elif(model == 'DS_domain'):\n",
    "            LOSOCV.append([training_images, training_flow_images, training_labels, training_domain_labels, verification_images, verification_flow_images, verification_labels, verification_domain_labels])\n",
    "        else:\n",
    "            LOSOCV.append([training_images, training_labels, verification_images, verification_labels])\n",
    "\n",
    "        \n",
    "#     if(model == 'DS'):\n",
    "#         for i in range(len(subject_boundary) - 1):\n",
    "#             training_images = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 1, image_rows, image_columns, image_depth))\n",
    "#             training_flow_images = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 1, flow_rows, flow_columns, flow_depth))\n",
    "#             verification_images = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 1, image_rows, image_columns, image_depth))\n",
    "#             verification_flow_images = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 1, flow_rows, flow_columns, flow_depth))\n",
    "#             training_labels = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 3))\n",
    "#             verification_labels = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 3))\n",
    "#             for j in range(sample):\n",
    "#                 if (j >= subject_boundary[i] and j < subject_boundary[i + 1]):\n",
    "#                     verification_images[j-subject_boundary[i]][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "#                     verification_flow_images[j-subject_boundary[i]][0][:][:][:] = flow_set[j][0][:][:][:]\n",
    "#                     verification_labels[j-subject_boundary[i]][:] = labels[j][:]\n",
    "#                 elif (j < subject_boundary[i]):\n",
    "#                     training_images[j][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "#                     training_labels[j][:] = labels[j][:]\n",
    "#                     training_flow_images[j][0][:][:][:] = flow_set[j][0][:][:][:]\n",
    "#                 else:\n",
    "#                     training_images[j - subject_boundary[i+1] + subject_boundary[i]][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "#                     training_labels[j - subject_boundary[i+1] + subject_boundary[i]][:] = labels[j][:]\n",
    "#                     training_flow_images[j - subject_boundary[i+1] + subject_boundary[i]][0][:][:][:] = flow_set[j][0][:][:][:]\n",
    "\n",
    "#             if(CK == 'CK+' or (isinstance(CK, list) and CK)):\n",
    "#                 for k in range(327):\n",
    "#                     training_images[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][0][:][:][:] = CK_training_set[k][0][:][:][:]\n",
    "#                     training_flow_images[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][0][:][:][:] = CK_flow[k][0][:][:][:]\n",
    "#                     training_labels[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][:] = CK_labels[k][:]\n",
    "                    \n",
    "#             LOSOCV.append([training_images, training_flow_images, training_labels, verification_images, verification_flow_images, verification_labels])\n",
    "    \n",
    "#     else:\n",
    "#         training_images = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 1, image_rows, image_columns, image_depth))\n",
    "#         verification_images = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 1, image_rows, image_columns, image_depth))\n",
    "#         training_labels = np.zeros((sample - (subject_boundary[i + 1] - subject_boundary[i]) + CK_num, 3))\n",
    "#         verification_labels = np.zeros((subject_boundary[i + 1] - subject_boundary[i], 3))\n",
    "#         for j in range(133):\n",
    "#             if (j >= subject_boundary[i] and j < subject_boundary[i + 1]):\n",
    "#                 verification_images[j-subject_boundary[i]][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "#                 verification_labels[j-subject_boundary[i]][:] = labels[j][:]\n",
    "#             elif (j < subject_boundary[i]):\n",
    "#                 training_images[j][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "#                 training_labels[j][:] = labels[j][:]\n",
    "#             else:\n",
    "#                 training_images[j - subject_boundary[i+1] + subject_boundary[i]][0][:][:][:] = training_set[j][0][:][:][:]\n",
    "#                 training_labels[j - subject_boundary[i+1] + subject_boundary[i]][:] = labels[j][:]\n",
    "               \n",
    "#         if(CK == 'CK+' or (isinstance(CK, list) and CK)):\n",
    "#             for k in range(327):\n",
    "#                 training_images[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][0][:][:][:] = CK_training_set[k][0][:][:][:]\n",
    "#                 training_labels[sample - (subject_boundary[i + 1] - subject_boundary[i]) + k][:] = CK_labels[k][:]\n",
    "\n",
    "#         LOSOCV.append([training_images, training_labels, verification_images, verification_labels])\n",
    "    \n",
    "    return LOSOCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(LOSOCV, filepathdir):\n",
    "    i = 0\n",
    "    for example in LOSOCV:\n",
    "        if (len(LOSOCV[0]) == 6):\n",
    "            if(i == 0):\n",
    "                model = Model.DS()\n",
    "                model.save_weights(filepathdir + 'model.h5')\n",
    "            else:\n",
    "                model.load_weights(filepathdir + 'model.h5')\n",
    "            filepath= filepathdir + \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}-LOSO-DS-SAMM-\" + str(i) +\".hdf5\"\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "            hist = model.fit(x = [example[0], example[1]] ,y = example[2], validation_data = ([example[3], example[4]], example[5]), callbacks=callbacks_list,verbose = 1, batch_size = 8, epochs = 200, shuffle=True)\n",
    "        elif(len(LOSOCV[0]) == 4):\n",
    "            if(i == 0):\n",
    "                model = Model.origin()\n",
    "                model.save_weights(filepathdir + 'model.h5')\n",
    "            else:\n",
    "                model.load_weights(filepathdir + 'model.h5')\n",
    "            filepath= filepathdir + \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}-LOSO-DS-SMIC-\" + str(i) +\".hdf5\"\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "            hist = model.fit(example[0], example[1] , validation_data = (example[2], example[3]), callbacks=callbacks_list,verbose = 1, batch_size = 8, epochs = 200, shuffle=True)\n",
    "        elif(len(LOSOCV[0]) == 8):\n",
    "            if(i == 0):\n",
    "                model = Model.DS_domain()\n",
    "                model.save_weights(filepathdir + 'model.h5')\n",
    "            else:\n",
    "                model.load_weights(filepathdir + 'model.h5')\n",
    "            filepath= filepathdir + \"weights-improvement-{epoch:02d}-{val_activation_accuracy:.2f}-LOSO-DS_domain-SAMM-\" + str(i) +\".hdf5\"\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_activation_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "            hist = model.fit(x = [example[0], example[1]] ,y = [example[2], example[3]], validation_data = ([example[4], example[5]], [example[6], example[7]]), callbacks=callbacks_list,verbose = 1, batch_size = 8, epochs = 150, shuffle=True)\n",
    "\n",
    "        i = i + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
