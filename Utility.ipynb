{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import scipy.signal as signal\n",
    "import scipy.fftpack as fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlow(interval, video_tensor):\n",
    "    count = 0\n",
    "    flow = []\n",
    "    while(count + interval < len(video_tensor)):\n",
    "        inst_flow = cv2.calcOpticalFlowFarneback(cv2.cvtColor(np.float32(video_tensor[count]), cv2.COLOR_BGR2GRAY), cv2.cvtColor(np.float32(video_tensor[count+interval]), cv2.COLOR_BGR2GRAY), flow=None,\n",
    "                                                        pyr_scale=0.5, levels=1, winsize=15,\n",
    "                                                        iterations=2,\n",
    "                                                        poly_n=5, poly_sigma=1.1, flags=0)\n",
    "        flow.append(inst_flow[...,0])\n",
    "        flow.append(inst_flow[...,1])\n",
    "        count = count + interval\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Magnification\n",
    "#convert RBG to YIQ\n",
    "def rgb2ntsc(src):\n",
    "    [rows,cols]=src.shape[:2]\n",
    "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
    "    T = np.array([[0.114, 0.587, 0.298], [-0.321, -0.275, 0.596], [0.311, -0.528, 0.212]])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dst[i, j]=np.dot(T,src[i,j])\n",
    "    return dst\n",
    "\n",
    "#convert YIQ to RBG\n",
    "def ntsc2rbg(src):\n",
    "    [rows, cols] = src.shape[:2]\n",
    "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
    "    T = np.array([[1, -1.108, 1.705], [1, -0.272, -0.647], [1, 0.956, 0.620]])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dst[i, j]=np.dot(T,src[i,j])\n",
    "    return dst\n",
    "\n",
    "#Build Gaussian Pyramid\n",
    "def build_gaussian_pyramid(src,level=3):\n",
    "    s=src.copy()\n",
    "    pyramid=[s]\n",
    "    for i in range(level):\n",
    "        s=cv2.pyrDown(s)\n",
    "        pyramid.append(s)\n",
    "    return pyramid\n",
    "\n",
    "#Build Laplacian Pyramid\n",
    "#Build Laplacian Pyramid\n",
    "def build_laplacian_pyramid(src,levels=3):\n",
    "    gaussianPyramid = build_gaussian_pyramid(src, levels)\n",
    "    pyramid=[]\n",
    "    for i in range(levels,0,-1):\n",
    "        GE=cv2.pyrUp(gaussianPyramid[i])\n",
    "        L=cv2.subtract(gaussianPyramid[i-1],GE)\n",
    "        pyramid.append(L)\n",
    "    return pyramid\n",
    "\n",
    "#load video from file\n",
    "def load_video(video_filename):\n",
    "    cap=cv2.VideoCapture(video_filename)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    video_tensor=np.zeros((frame_count,height,width,3),dtype='float')\n",
    "    x=0\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        if ret is True:\n",
    "            video_tensor[x]=frame\n",
    "            x+=1\n",
    "        else:\n",
    "            break\n",
    "    return video_tensor,fps\n",
    "\n",
    "# apply temporal ideal bandpass filter to gaussian video\n",
    "def temporal_ideal_filter(tensor,low,high,fps,axis=0):\n",
    "    fft=fftpack.fft(tensor,axis=axis)\n",
    "    frequencies = fftpack.fftfreq(tensor.shape[0], d=1.0 / fps)\n",
    "    bound_low = (np.abs(frequencies - low)).argmin()\n",
    "    bound_high = (np.abs(frequencies - high)).argmin()\n",
    "    fft[:bound_low] = 0\n",
    "    fft[bound_high:-bound_high] = 0\n",
    "    fft[-bound_low:] = 0\n",
    "    iff=fftpack.ifft(fft, axis=axis)\n",
    "    return np.abs(iff)\n",
    "\n",
    "# build gaussian pyramid for video\n",
    "def gaussian_video(video_tensor,levels=3):\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        frame=video_tensor[i]\n",
    "        pyr=build_gaussian_pyramid(frame,level=levels)\n",
    "        gaussian_frame=pyr[-1]\n",
    "        if i==0:\n",
    "            vid_data=np.zeros((video_tensor.shape[0],gaussian_frame.shape[0],gaussian_frame.shape[1],3))\n",
    "        vid_data[i]=gaussian_frame\n",
    "    return vid_data\n",
    "\n",
    "#amplify the video\n",
    "def amplify_video(gaussian_vid,amplification=50):\n",
    "    return gaussian_vid*amplification\n",
    "\n",
    "#reconstract video from original video and gaussian video\n",
    "def reconstract_video(amp_video,origin_video,levels=3):\n",
    "    final_video=np.zeros(origin_video.shape)\n",
    "    for i in range(0,amp_video.shape[0]):\n",
    "        img = amp_video[i]\n",
    "        for x in range(levels):\n",
    "            img=cv2.pyrUp(img)\n",
    "        img=img+origin_video[i]\n",
    "        final_video[i]=img\n",
    "    return final_video\n",
    "\n",
    "#save video to files\n",
    "def save_video(video_tensor):\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    [height,width]=video_tensor[0].shape[0:2]\n",
    "    writer = cv2.VideoWriter(\"out.avi\", fourcc, 30, (width, height), 1)\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        writer.write(cv2.convertScaleAbs(video_tensor[i]))\n",
    "    writer.release()\n",
    "\n",
    "#magnify color\n",
    "def magnify_color(video_name,low,high,levels=3,amplification=20):\n",
    "    t,f=load_video(video_name)\n",
    "    gau_video=gaussian_video(t,levels=levels)\n",
    "    filtered_tensor=temporal_ideal_filter(gau_video,low,high,f)\n",
    "    amplified_video=amplify_video(filtered_tensor,amplification=amplification)\n",
    "    final=reconstract_video(amplified_video,t,levels=3)\n",
    "    save_video(final)\n",
    "\n",
    "#build laplacian pyramid for video\n",
    "def laplacian_video(video_tensor,levels=3):\n",
    "    tensor_list=[]\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        frame=video_tensor[i]\n",
    "        pyr=build_laplacian_pyramid(frame,levels=levels)\n",
    "        if i==0:\n",
    "            for k in range(levels):\n",
    "                tensor_list.append(np.zeros((video_tensor.shape[0],pyr[k].shape[0],pyr[k].shape[1],3)))\n",
    "        for n in range(levels):\n",
    "            tensor_list[n][i] = pyr[n]\n",
    "    return tensor_list\n",
    "\n",
    "#butterworth bandpass filter\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    omega = 0.5 * fs\n",
    "    low = lowcut / omega\n",
    "    high = highcut / omega\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    y = signal.lfilter(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "#reconstract video from laplacian pyramid\n",
    "def reconstract_from_tensorlist(filter_tensor_list,levels=3):\n",
    "    final=np.zeros(filter_tensor_list[-1].shape)\n",
    "    for i in range(filter_tensor_list[0].shape[0]):\n",
    "        up = filter_tensor_list[0][i]\n",
    "        for n in range(levels-1):\n",
    "            up=cv2.pyrUp(up)+filter_tensor_list[n + 1][i]#可以改为up=cv2.pyrUp(up)\n",
    "        final[i]=up\n",
    "    return final\n",
    "\n",
    "#magnify motion\n",
    "def magnify_motion(t, f, low, high,levels=3,amplification=20):\n",
    "    lap_video_list=laplacian_video(t,levels=levels)\n",
    "    filter_tensor_list=[]\n",
    "    for i in range(levels):\n",
    "        filter_tensor=butter_bandpass_filter(lap_video_list[i],low,high,f)\n",
    "        filter_tensor*=amplification\n",
    "        filter_tensor_list.append(filter_tensor)\n",
    "    recon=reconstract_from_tensorlist(filter_tensor_list)\n",
    "    final=t+recon\n",
    "    return final\n",
    "\n",
    "#magnify video\n",
    "def magnify_video(video_tensor, fps, low, high, image_rows, image_columns, levels=3, amplification=20):\n",
    "\n",
    "    frames = []\n",
    "    magnified = magnify_motion(video_tensor, fps, 0.4, 3,levels=3,amplification=20)\n",
    "\n",
    "    for i in range(magnified.shape[0]):\n",
    "        imageresize = cv2.resize(magnified[i], (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
    "        img_float32 = np.float32(imageresize)\n",
    "        grayimage = cv2.cvtColor(img_float32, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(grayimage)\n",
    "\n",
    "    frames = np.asarray(frames)\n",
    "    \n",
    "    return frames\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
